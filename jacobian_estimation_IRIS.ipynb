{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess Iris dataset\n",
    "n_gauss = 3  # Equal to number of classes\n",
    "dim = 3  # 4 is maximum dimension\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :dim]  # Use only the first two features\n",
    "# X = iris.data  # Use only the first two features\n",
    "D = StandardScaler().fit_transform(X)  # Standardize features\n",
    "\n",
    "c = iris.target  # Class labels\n",
    "\n",
    "class_label= ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# colors = ['r', 'g', 'b']  # Red, Green, Blue\n",
    "colors = ['#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#00FFFF', '#FF00FF', '#000000']\n",
    "# Create a figure and 3D axis\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Define colors for each Gaussian distribution\n",
    "\n",
    "# Loop through each Gaussian to plot points with corresponding color\n",
    "for i in range(n_gauss):\n",
    "    ax.scatter(D[c == i, 0], D[c == i, 1], D[c == i, 2], color=colors[i], label=class_label[i])\n",
    "    # ax.scatter(D[:,0], D[:,1], D[:,2], c=c)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.set_title('3D Scatter Plot of Data Points from Three Gaussian Distributions')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sne = umap.UMAP(\n",
    "    n_components=2,     # Targeting 2D projection\n",
    "    n_neighbors=10,     # Similar to t-SNE perplexity\n",
    "    min_dist=0.1,       # Controls the compactness of the clusters\n",
    "    init=\"random\",\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "\n",
    "# Apply UMAP on the 3D Gaussian data `D`\n",
    "S = t_sne.fit_transform(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the t-SNE results with the same color scheme\n",
    "%matplotlib qt\n",
    "\n",
    "# colors = ['r', 'g', 'b','']  # Red, Green, Blue\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_gauss):\n",
    "    plt.scatter(S[c == i, 0], S[c == i, 1], color=colors[i], label=class_label[i])\n",
    "    # plt.scatter(S[c == i, 0], S[c == i, 1], label=f'Gaussian {i+1}')\n",
    "\n",
    "plt.title('t-SNE Visualization of 3D Gaussian Distributions into 2D')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 2D Grid for Jacobian Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define min and max values\n",
    "x_min, x_max = np.min(S[:, 0]), np.max(S[:, 0])\n",
    "y_min, y_max = np.min(S[:, 1]), np.max(S[:, 1])\n",
    "print(x_min, x_max)\n",
    "print(y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid resolution\n",
    "num_grid_points = 100\n",
    "\n",
    "# Generate grid\n",
    "x_vals = np.linspace(x_min, x_max, num_grid_points)\n",
    "y_vals = np.linspace(y_min, y_max, num_grid_points)\n",
    "xx, yy = np.meshgrid(x_vals, y_vals)\n",
    "print(yy.shape)\n",
    "print(y_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Visualize the grid on top of the t-SNE data\n",
    "plt.scatter(S[:, 0], S[:, 1], c='blue', s=10, label=\"t-SNE Output\")\n",
    "plt.scatter(xx, yy, c='red', s=5, label=\"Grid Points\")\n",
    "plt.title(\"2D t-SNE Output with Grid Points\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Inverse Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the MLP inverse_model\n",
    "class NNinv(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NNinv, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),  # Input to first hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),  # First hidden layer to second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),  # Second hidden layer to third hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),  # Third hidden layer to fourth hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_size),  # Fifth hidden layer to output\n",
    "            nn.Sigmoid()  # Output layer with sigmoid activation\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, c_train, c_test = train_test_split(S, D,c, test_size=0.33, random_state=42, stratify=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(c_train.shape)\n",
    "print(c_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# Assuming c_train is your array\n",
    "unique_values, counts = np.unique(c_test, return_counts=True)\n",
    "\n",
    "# Display the unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Class {value}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_size = 2  # Example input size (can be changed)\n",
    "output_size = dim   # Binary classification (sigmoid output for single output)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "batch_size = 64\n",
    "t_X_train = torch.tensor(X_train)\n",
    "t_y_train = torch.tensor(y_train)\n",
    "dataset = TensorDataset(t_X_train, t_y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate the inverse_model, loss function, and optimizer\n",
    "inverse_model = NNinv(input_size, output_size)\n",
    "loss_fn = nn.L1Loss()  # Mean Absolute Error (MAE)\n",
    "optimizer = optim.Adam(inverse_model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs to train\n",
    "num_epochs = 2000\n",
    "# num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        # Forward pass\n",
    "        outputs = inverse_model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X_test = torch.tensor(X_test)\n",
    "t_y_test = torch.tensor(y_test)\n",
    "outputs_test = inverse_model(t_X_test)\n",
    "loss_test = loss_fn(outputs_test, t_y_test)\n",
    "print(loss_test/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Inverse Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Create a figure and 3D axis\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Define colors for each Gaussian distribution\n",
    "# colors = ['r', 'g', 'b']  # Red, Green, Blue\n",
    "\n",
    "\n",
    "output_fin = outputs_test.detach().numpy()\n",
    "# Loop through each Gaussian to plot points with corresponding color\n",
    "for i in range(n_gauss):\n",
    "    ax.scatter(t_y_test[c_test == i, 0], t_y_test[c_test == i, 1], t_y_test[c_test == i, 2], color=colors[i], label=f'Actual_Gaussian {i+1}')\n",
    "    # ax.scatter(output_fin[c_test == i, 0], output_fin[c_test == i, 1], output_fin[c_test == i, 2], color='orange', label=f'Predicted_Gaussian {i+1}')\n",
    "\n",
    "ax.scatter(output_fin[:, 0], output_fin[:, 1], output_fin[:, 2], color='orange', label=f'Predicted_Gaussians')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.set_title('TSNE \\n Actual Vs Prediction')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating 2D projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spread_points(S, labels, num_new_points_per_cluster=5, spread_factor=0.5):\n",
    "    \"\"\"\n",
    "    Generate new points around the spread of the Gaussian clusters in 2D t-SNE space.\n",
    "    \n",
    "    Parameters:\n",
    "    S (np.array): 2D t-SNE points (original).\n",
    "    labels (np.array): Labels for the original points, corresponding to Gaussian clusters.\n",
    "    num_new_points_per_cluster (int): Number of new points to generate per Gaussian cluster.\n",
    "    spread_factor (float): Spread factor controlling the variance of new points.\n",
    "    \n",
    "    Returns:\n",
    "    new_points (np.array): Newly generated points spread around each cluster.\n",
    "    new_labels (np.array): Labels corresponding to the new points.\n",
    "    \"\"\"\n",
    "    new_points = []\n",
    "    new_labels = []\n",
    "    \n",
    "    # Get the unique labels (each label corresponds to one Gaussian)\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Get the points that belong to the current Gaussian cluster\n",
    "        cluster_points = S[labels == label]\n",
    "        \n",
    "        # Calculate covariance matrix for the current cluster\n",
    "        cluster_cov = np.cov(cluster_points.T)\n",
    "\n",
    "        for _ in range(num_new_points_per_cluster):\n",
    "            # Randomly choose a point within the cluster\n",
    "            random_point = cluster_points[np.random.randint(len(cluster_points))]\n",
    "            \n",
    "            # Generate a random offset using the covariance matrix to create a spread\n",
    "            offset = np.random.multivariate_normal([0, 0], spread_factor * cluster_cov)\n",
    "\n",
    "            # Add the offset to the selected random point to create a new point\n",
    "            new_point = random_point + offset\n",
    "            new_points.append(new_point)\n",
    "            new_labels.append(label)  # Assign the same label as the original points\n",
    "    \n",
    "    return np.array(new_points), np.array(new_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points, new_labels = generate_spread_points(S, c, num_new_points_per_cluster=20, spread_factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = ['$G1$', '$G2$', '$G3$', '$G4$', '$G5$', '$G6$', '$G7$']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_gauss):\n",
    "    plt.scatter(S[c == i, 0], S[c == i, 1], color=colors[i], label=f'Gaussian {i+1}')\n",
    "\n",
    "    # Plot new points\n",
    "    plt.scatter(new_points[new_labels == i, 0], new_points[new_labels == i, 1], color=colors[i], marker = markers[i] , s = 100, edgecolors='black', label= f'New Points_Gaussian {i+1}')\n",
    "\n",
    "# plt.scatter(new_points[:, 0], new_points[:, 1], color='brown', label=\"New Points\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Original and Generated Points in 2D t-SNE Space\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply train model on new points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points_test = torch.tensor(new_points).float()\n",
    "outputs_new_points = inverse_model(new_points_test)\n",
    "outputs_new_points =outputs_new_points.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Create a figure and 3D axis\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# # Define colors for each Gaussian distribution\n",
    "# colors = ['r', 'g', 'b']  # Red, Green, Blue\n",
    "\n",
    "# Loop through each Gaussian to plot points with corresponding color\n",
    "for i in range(n_gauss):\n",
    "    ax.scatter(D[c == i, 0], D[c == i, 1], D[c == i, 2], color=colors[i], alpha=0.7, label=f'Gaussian {i+1}')\n",
    "    ax.scatter(outputs_new_points[new_labels == i, 0], outputs_new_points[new_labels == i, 1], outputs_new_points[new_labels == i, 2], marker=markers[i],alpha=1.0, s=150, edgecolors='black', label=f'New_points_Gaussian {i+1}')\n",
    "\n",
    "# ax.scatter(outputs_new_points[:, 0], outputs_new_points[:, 1], outputs_new_points[:, 2], color='k', label=f'Predicted_Gaussian {i+1}')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.set_title(' New points (2D TSNE) mapping into 3D Gaussian Distributions')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian(x, y):\n",
    "    \"\"\"\n",
    "    Computes the Jacobian matrix for each point in the grid.\n",
    "    \n",
    "    Args:\n",
    "        grid_points (ndarray): A 2D array of shape (n_points, 2) representing the grid points.\n",
    "\n",
    "    Returns:\n",
    "        jacobian_matrices (list): A list of jacobian matrices for each grid point.\n",
    "    \"\"\"\n",
    "    jacobian_matrices = []\n",
    "    \n",
    "    # Define the model's forward pass to use autograd\n",
    "    def model_forward(input):\n",
    "        return inverse_model(input)  # Model's forward pass\n",
    "    \n",
    "    # Iterate through the grid points\n",
    "    # for point in grid_points:\n",
    "    point_tensor = torch.tensor([x, y], dtype=torch.float32, requires_grad=True)  # (1, 2) tensor\n",
    "    \n",
    "    # Compute the Jacobian using autograd's jacobian function\n",
    "    jacobian = torch.autograd.functional.jacobian(model_forward, point_tensor)\n",
    "    \n",
    "        # The output of jacobian will have shape (1, 3, 2), so we need to squeeze to get (3, 2)\n",
    "        # jacobian_matrices.append(jacobian.squeeze(0))  # Remove the batch dimension\n",
    "    \n",
    "    return jacobian\n",
    "\n",
    "def compute_jacobian_implement(x, y, eps=1e-5):\n",
    "    # Create tensor point for cloning\n",
    "    point = torch.tensor([[x, y]], dtype=torch.float32)\n",
    "\n",
    "    # Partial derivative w.r.t. x using five-point stencil\n",
    "    f_x_2plus = inverse_model(torch.tensor([[x + 2 * eps, y]], dtype=torch.float32))\n",
    "    f_x_plus = inverse_model(torch.tensor([[x + eps, y]], dtype=torch.float32))\n",
    "    f_x_minus = inverse_model(torch.tensor([[x - eps, y]], dtype=torch.float32))\n",
    "    f_x_2minus = inverse_model(torch.tensor([[x - 2 * eps, y]], dtype=torch.float32))\n",
    "    \n",
    "    df_dx = (-f_x_2plus + 8 * f_x_plus - 8 * f_x_minus + f_x_2minus) / (12 * eps)\n",
    "\n",
    "    # Partial derivative w.r.t. y using five-point stencil\n",
    "    f_y_2plus = inverse_model(torch.tensor([[x, y + 2 * eps]], dtype=torch.float32))\n",
    "    f_y_plus = inverse_model(torch.tensor([[x, y + eps]], dtype=torch.float32))\n",
    "    f_y_minus = inverse_model(torch.tensor([[x, y - eps]], dtype=torch.float32))\n",
    "    f_y_2minus = inverse_model(torch.tensor([[x, y - 2 * eps]], dtype=torch.float32))\n",
    "    \n",
    "    df_dy = (-f_y_2plus + 8 * f_y_plus - 8 * f_y_minus + f_y_2minus) / (12 * eps)\n",
    "\n",
    "    # Stack results to form Jacobian matrix\n",
    "    jacobian = torch.stack([df_dx.squeeze(), df_dy.squeeze()], dim=1)\n",
    "    \n",
    "    return jacobian.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Jacobians over the grid and store results\n",
    "jacobians = []\n",
    "for i in range(num_grid_points):\n",
    "    for j in range(num_grid_points):\n",
    "        x, y = xx[i, j], yy[i, j]\n",
    "        # print(x,y)\n",
    "        jacobian = compute_jacobian(x, y)\n",
    "        # jacobian = compute_jacobian_implement(x, y, 1e-5)\n",
    "        # print(jacobian)\n",
    "        jacobians.append(jacobian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Jacobian [num_girds, num_grids, output_dim, input_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the list of numpy arrays into a list of PyTorch tensors\n",
    "jacobian_tensors = [torch.tensor(jacob) for jacob in jacobians]\n",
    "\n",
    "# Convert the list into a 3D tensor\n",
    "jacobian_tensor = torch.stack(jacobian_tensors)  # Shape will be [num_grids * num_grids, out, inp]\n",
    "\n",
    "# Reshape the tensor to [num_grids, num_grids, 3, 2]\n",
    "jacobian_tensor_reshaped = jacobian_tensor.view(num_grid_points, num_grid_points, dim, 2)\n",
    "jacobian_tensor_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store singular values, U and V matrices for each Jacobian\n",
    "singular_values_list = []\n",
    "U_matrices = []\n",
    "V_matrices = []\n",
    "\n",
    "# Iterate over each grid point and apply SVD\n",
    "for i in range(jacobian_tensor_reshaped.shape[0]):\n",
    "    for j in range(jacobian_tensor_reshaped.shape[1]):\n",
    "        jacobian_matrix = jacobian_tensor_reshaped[i, j]  # Shape: (3, 2)\n",
    "        \n",
    "        \n",
    "        # Perform SVD\n",
    "        U, SV, Vt = torch.linalg.svd(jacobian_matrix, full_matrices=False)\n",
    "        # print(SV)\n",
    "        # np.savetxt('jacob_matrix'+ str(i),jacobian_matrix)\n",
    "    \n",
    "        # break\n",
    "        # Store the singular values and U, V matrices\n",
    "        singular_values_list.append(SV)\n",
    "        U_matrices.append(U)\n",
    "        V_matrices.append(Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(U_matrices[0].shape)\n",
    "print(singular_values_list[0].shape)\n",
    "print(V_matrices[0].shape)\n",
    "\n",
    "print(len(U_matrices))\n",
    "print(len(singular_values_list))\n",
    "print(len(V_matrices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define min and max values\n",
    "# x_min, x_max = np.min(S[:, 0]), np.max(S[:, 0])\n",
    "# y_min, y_max = np.min(S[:, 1]), np.max(S[:, 1])\n",
    "# print(x_min, x_max)\n",
    "# print(y_min, y_max)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reshape singular values to the grid's shape for visualization\n",
    "# Extract the largest singular value for each point in the grid\n",
    "largest_singular_values = np.array([s[0] for s in singular_values_list]).reshape(num_grid_points, num_grid_points)\n",
    "\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(largest_singular_values,\n",
    "           extent=(x_min, x_max, y_min, y_max),\n",
    "           origin='lower', \n",
    "           cmap='hot', \n",
    "           interpolation='nearest')\n",
    "plt.colorbar(label=\"Largest Singular Value\")\n",
    "plt.xlabel(\"Grid X\")\n",
    "plt.ylabel(\"Grid Y\")\n",
    "plt.title(\"Heatmap of Jacobian Singular Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlayplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define min and max values\n",
    "x_min, x_max = np.min(S[:, 0]), np.max(S[:, 0])\n",
    "y_min, y_max = np.min(S[:, 1]), np.max(S[:, 1])\n",
    "print(x_min, x_max)\n",
    "print(y_min, y_max)\n",
    "\n",
    "# Define grid resolution \n",
    "num_grid_points = 100\n",
    "\n",
    "# Generate grid\n",
    "x_vals = np.linspace(x_min, x_max, num_grid_points)\n",
    "y_vals = np.linspace(y_min, y_max, num_grid_points)\n",
    "xx, yy = np.meshgrid(x_vals, y_vals)\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "jacobian_norms = np.zeros(len(grid_points))\n",
    "for idx, point in enumerate(grid_points):\n",
    "    point_tensor = torch.tensor(point, dtype=torch.float32, requires_grad=True).view(1, 2)\n",
    "    \n",
    "    # Compute the Jacobian for the current point\n",
    "    jacobian = torch.autograd.functional.jacobian(lambda x: inverse_model(x), point_tensor)\n",
    "    \n",
    "    # Reshape Jacobian to 2D: (output_dim, input_dim)\n",
    "    jacobian_2d = jacobian.view(dim, 2)  # Assuming output is (1, 3), input is (1, 2)\n",
    "    \n",
    "    # Compute spectral norm (largest singular value)\n",
    "    jacobian_norms[idx] = torch.linalg.norm(jacobian_2d, ord=2).item()\n",
    "\n",
    "jacobian_norms = jacobian_norms.reshape(xx.shape)\n",
    "\n",
    "# Step 4: Plot heatmap with t-SNE points overlayed\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot heatmap\n",
    "plt.imshow(\n",
    "    jacobian_norms,\n",
    "    extent=(x_min, x_max, y_min, y_max),\n",
    "    origin='lower',\n",
    "    cmap='hot',\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.colorbar(label='Spectral Norm of Jacobian')\n",
    "\n",
    "# Overlay t-SNE points\n",
    "# plt.scatter(S[:, 0], S[:, 1], c='blue', edgecolor='k', label='t-SNE points')\n",
    "\n",
    "for i in range(n_gauss):\n",
    "    plt.scatter(S[c == i, 0], S[c == i, 1], color=colors[i], label=class_label[i])\n",
    "\n",
    "\n",
    "# Labels and title\n",
    "plt.title(\"Overlaying t-SNE points on Jacobian Heatmap\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobian estiamtion Analytically SYmbolically (IRIS Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess Iris dataset\n",
    "n_gauss = 3  # Equal to number of classes\n",
    "dim = 3  # 4 is maximum dimension\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :dim]  # Use only the first two features\n",
    "# X = iris.data  # Use only the first two features\n",
    "D = StandardScaler().fit_transform(X)  # Standardize features\n",
    "\n",
    "c = iris.target  # Class labels\n",
    "\n",
    "class_label= ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Analytic, Symbolic, Autograd, our implementation for Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New analytic function\n",
    "def analytic_function(point):\n",
    "    x, y = point[:, 0], point[:, 1]\n",
    "    z1 = x**2 * y + torch.sin(x * y)\n",
    "    z2 = y**2 * x + torch.cos(x * y)\n",
    "    return torch.stack([z1, z2], dim=1)\n",
    "\n",
    "# Symbolic Jacobian\n",
    "def symbolic_jacobian(x, y):\n",
    "    return np.array([\n",
    "        [2 * x * y + y * np.cos(x * y), x**2 + x * np.cos(x * y)],\n",
    "        [y**2 + y * np.cos(x * y), 2 * y * x - x * np.sin(x * y)],\n",
    "    ])\n",
    "\n",
    "\n",
    "# Numerical Jacobian using autograd\n",
    "def compute_jacobian_autograd(func, point):\n",
    "    point_tensor = torch.tensor([point], dtype=torch.float32, requires_grad=True)\n",
    "    jacobian = torch.autograd.functional.jacobian(func, point_tensor)\n",
    "    return jacobian.squeeze(0).squeeze(1).detach().numpy()\n",
    "\n",
    "# Five-point stencil for numerical Jacobian\n",
    "def compute_jacobian_implement(x, y, eps=1e-5):\n",
    "    # Compute partial derivatives using five-point stencil\n",
    "    f_x_2plus = analytic_function(torch.tensor([[x + 2 * eps, y]], dtype=torch.float32))\n",
    "    f_x_plus = analytic_function(torch.tensor([[x + eps, y]], dtype=torch.float32))\n",
    "    f_x_minus = analytic_function(torch.tensor([[x - eps, y]], dtype=torch.float32))\n",
    "    f_x_2minus = analytic_function(torch.tensor([[x - 2 * eps, y]], dtype=torch.float32))\n",
    "    df_dx = (-f_x_2plus + 8 * f_x_plus - 8 * f_x_minus + f_x_2minus) / (12 * eps)\n",
    "\n",
    "    f_y_2plus = analytic_function(torch.tensor([[x, y + 2 * eps]], dtype=torch.float32))\n",
    "    f_y_plus = analytic_function(torch.tensor([[x, y + eps]], dtype=torch.float32))\n",
    "    f_y_minus = analytic_function(torch.tensor([[x, y - eps]], dtype=torch.float32))\n",
    "    f_y_2minus = analytic_function(torch.tensor([[x, y - 2 * eps]], dtype=torch.float32))\n",
    "    df_dy = (-f_y_2plus + 8 * f_y_plus - 8 * f_y_minus + f_y_2minus) / (12 * eps)\n",
    "\n",
    "    return torch.stack([df_dx.squeeze(), df_dy.squeeze()], dim=1).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Spectral Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_norm_symbolic = np.zeros(X.shape[0])\n",
    "spectral_norm_autograd = np.zeros_like(spectral_norm_symbolic)\n",
    "spectral_norm_implement = np.zeros_like(spectral_norm_symbolic)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    symbolic_J = jacobian_symbolic[i]\n",
    "    autograd_J = jacobian_autograd[i]\n",
    "    implement_J = jacobian_implement[i]\n",
    "\n",
    "    spectral_norm_symbolic[i] = np.linalg.norm(symbolic_J, ord=2)\n",
    "    spectral_norm_autograd[i] = np.linalg.norm(autograd_J, ord=2)\n",
    "    spectral_norm_implement[i] = np.linalg.norm(implement_J, ord=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Load and preprocess Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :2]  # Use only the first two features\n",
    "y = iris.target  # Target labels\n",
    "X = StandardScaler().fit_transform(X)  # Standardize features\n",
    "\n",
    "# Define an analytic function for transformation\n",
    "def analytic_function(point):\n",
    "    x, y = point[:, 0], point[:, 1]\n",
    "    z1 = x**2 * y + torch.sin(x * y)\n",
    "    z2 = y**2 * x + torch.cos(x * y)\n",
    "    return torch.stack([z1, z2], dim=1)\n",
    "\n",
    "# Symbolic Jacobian\n",
    "def symbolic_jacobian(x, y):\n",
    "    return np.array([\n",
    "        [2 * x * y + y * np.cos(x * y), x**2 + x * np.cos(x * y)],\n",
    "        [y**2 + y * np.cos(x * y), 2 * y * x - x * np.sin(x * y)],\n",
    "    ])\n",
    "\n",
    "# Numerical Jacobian using autograd\n",
    "def compute_jacobian_autograd(func, point):\n",
    "    point_tensor = torch.tensor([point], dtype=torch.float32, requires_grad=True)\n",
    "    jacobian = torch.autograd.functional.jacobian(func, point_tensor)\n",
    "    return jacobian.squeeze(0).squeeze(1).detach().numpy()\n",
    "\n",
    "# Numerical Jacobian using five-point stencil\n",
    "def compute_jacobian_implement(x, y, eps=1e-5):\n",
    "    f_x_2plus = analytic_function(torch.tensor([[x + 2 * eps, y]], dtype=torch.float32))\n",
    "    f_x_plus = analytic_function(torch.tensor([[x + eps, y]], dtype=torch.float32))\n",
    "    f_x_minus = analytic_function(torch.tensor([[x - eps, y]], dtype=torch.float32))\n",
    "    f_x_2minus = analytic_function(torch.tensor([[x - 2 * eps, y]], dtype=torch.float32))\n",
    "    df_dx = (-f_x_2plus + 8 * f_x_plus - 8 * f_x_minus + f_x_2minus) / (12 * eps)\n",
    "\n",
    "    f_y_2plus = analytic_function(torch.tensor([[x, y + 2 * eps]], dtype=torch.float32))\n",
    "    f_y_plus = analytic_function(torch.tensor([[x, y + eps]], dtype=torch.float32))\n",
    "    f_y_minus = analytic_function(torch.tensor([[x, y - eps]], dtype=torch.float32))\n",
    "    f_y_2minus = analytic_function(torch.tensor([[x, y - 2 * eps]], dtype=torch.float32))\n",
    "    df_dy = (-f_y_2plus + 8 * f_y_plus - 8 * f_y_minus + f_y_2minus) / (12 * eps)\n",
    "\n",
    "    return torch.stack([df_dx.squeeze(), df_dy.squeeze()], dim=1).detach().numpy()\n",
    "\n",
    "# Initialize Jacobians and spectral norms\n",
    "jacobian_symbolic = np.zeros((X.shape[0], 2, 2))\n",
    "jacobian_autograd = np.zeros_like(jacobian_symbolic)\n",
    "jacobian_implement = np.zeros_like(jacobian_symbolic)\n",
    "\n",
    "spectral_norm_symbolic = np.zeros(X.shape[0])\n",
    "spectral_norm_autograd = np.zeros_like(spectral_norm_symbolic)\n",
    "spectral_norm_implement = np.zeros_like(spectral_norm_symbolic)\n",
    "\n",
    "# Compute Jacobians and spectral norms\n",
    "for i, (x, y) in enumerate(X):\n",
    "    symbolic_J = symbolic_jacobian(x, y)\n",
    "    autograd_J = compute_jacobian_autograd(analytic_function, [x, y])\n",
    "    implement_J = compute_jacobian_implement(x, y, 1e-4)\n",
    "\n",
    "    jacobian_symbolic[i] = symbolic_J\n",
    "    jacobian_autograd[i] = autograd_J\n",
    "    jacobian_implement[i] = implement_J\n",
    "\n",
    "    spectral_norm_symbolic[i] = np.linalg.norm(symbolic_J, ord=2)\n",
    "    spectral_norm_autograd[i] = np.linalg.norm(autograd_J, ord=2)\n",
    "    spectral_norm_implement[i] = np.linalg.norm(implement_J, ord=2)\n",
    "\n",
    "# Create a grid for feature space\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Interpolate spectral norms onto the grid\n",
    "def interpolate_spectral_norm(norm_values):\n",
    "    return griddata(X[:, :2], norm_values, (xx, yy), method='cubic')\n",
    "\n",
    "spectral_norm_symbolic_interp = interpolate_spectral_norm(spectral_norm_symbolic)\n",
    "spectral_norm_autograd_interp = interpolate_spectral_norm(spectral_norm_autograd)\n",
    "spectral_norm_implement_interp = interpolate_spectral_norm(spectral_norm_implement)\n",
    "\n",
    "# Train a classifier to get decision boundaries\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X, y)\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Function to plot spectral norm heatmap with decision boundaries\n",
    "def plot_with_boundaries(spectral_norm_interp, method_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, spectral_norm_interp, levels=20, cmap='coolwarm', alpha=0.8)\n",
    "    plt.colorbar(label='Spectral Norm')\n",
    "    plt.contour(xx, yy, Z, levels=np.arange(4) - 0.5, cmap=ListedColormap(['black']), linestyles='--', linewidths=1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=ListedColormap(['red', 'green', 'blue']), s=20)\n",
    "    plt.title(f\"Spectral Norm and Decision Boundaries ({method_name})\")\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.show()\n",
    "\n",
    "# Plot results for each method\n",
    "plot_with_boundaries(spectral_norm_symbolic_interp, \"Symbolic\")\n",
    "plot_with_boundaries(spectral_norm_autograd_interp, \"Autograd\")\n",
    "plot_with_boundaries(spectral_norm_implement_interp, \"Our Implementation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse-projection-j9xKauoB-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
