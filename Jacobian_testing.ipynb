{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 3D Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.55601366  0.74146461 -0.58656169]\n",
      " [ 0.83722182 -0.02317762  0.22348773]]\n",
      "(600, 3)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "dim = 3\n",
    "n_gauss = 2\n",
    "n_pts_per_gauss = 300\n",
    "np.random.seed(5)\n",
    "\n",
    "# centers = np.zeros((n_gauss,dim))\n",
    "# for i in range(1,n_gauss):\n",
    "#     centers[i] = np.random.randint(0,2,3)\n",
    "centers = np.random.uniform(-1,1,size=(n_gauss,3))\n",
    "    \n",
    "print(centers)\n",
    "\n",
    "cov_m = [np.diag([0.01 for i in range(dim)]),np.diag([0.01 if i%2 !=0 else 0.01 for i in range(dim)])]\n",
    "\n",
    "D = np.zeros((n_pts_per_gauss*n_gauss,dim))\n",
    "c = np.zeros(n_pts_per_gauss*n_gauss)      # storage for labels\n",
    "for i in range(n_gauss):\n",
    "    k = np.random.randint(0,2,1)[0]\n",
    "    D[i*n_pts_per_gauss:(i+1)*n_pts_per_gauss] = np.random.multivariate_normal(centers[i],cov_m[k],n_pts_per_gauss)\n",
    "    c[i*n_pts_per_gauss:(i+1)*n_pts_per_gauss] = i \n",
    "D = (D-np.min(D,axis=0))/(np.max(D,axis=0)-np.min(D,axis=0))\n",
    "print(D.shape)\n",
    "print(c.shape)\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# colors = ['r', 'g', 'b']  # Red, Green, Blue\n",
    "colors = ['#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#00FFFF', '#FF00FF']\n",
    "# Create a figure and 3D axis\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Define colors for each Gaussian distribution\n",
    "\n",
    "# Loop through each Gaussian to plot points with corresponding color\n",
    "for i in range(n_gauss):\n",
    "    ax.scatter(D[c == i, 0], D[c == i, 1], D[c == i, 2], color=colors[i], label=f'Gaussian {i+1}')\n",
    "    # ax.scatter(D[:,0], D[:,1], D[:,2], c=c)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.set_title('3D Scatter Plot of Data Points from Three Gaussian Distributions')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sne = manifold.TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    init=\"random\",\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "S = t_sne.fit_transform(D)\n",
    "\n",
    "# Plotting the t-SNE results with the same color scheme\n",
    "%matplotlib qt\n",
    "\n",
    "# colors = ['r', 'g', 'b','']  # Red, Green, Blue\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(n_gauss):\n",
    "    plt.scatter(S[c == i, 0], S[c == i, 1], color=colors[i], label=f'Gaussian {i+1}')\n",
    "    # plt.scatter(S[c == i, 0], S[c == i, 1], label=f'Gaussian {i+1}')\n",
    "\n",
    "plt.title('t-SNE Visualization of 3D Gaussian Distributions into 2D')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Inverse Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 2)\n",
      "(198, 2)\n",
      "(402, 3)\n",
      "(198, 3)\n",
      "(402,)\n",
      "(198,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the MLP inverse_model\n",
    "class NNinv(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NNinv, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),  # Input to first hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),  # First hidden layer to second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),  # Second hidden layer to third hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),  # Third hidden layer to fourth hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_size),  # Fifth hidden layer to output\n",
    "            nn.Sigmoid()  # Output layer with sigmoid activation\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "X_train, X_test, y_train, y_test, c_train, c_test = train_test_split(S, D,c, test_size=0.33, random_state=42, stratify=c)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(c_train.shape)\n",
    "print(c_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1382\n",
      "Epoch [2/5], Loss: 0.0901\n",
      "Epoch [3/5], Loss: 0.0779\n",
      "Epoch [4/5], Loss: 0.0728\n",
      "Epoch [5/5], Loss: 0.0692\n",
      "Training complete.\n",
      "tensor(0.0004, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_size = 2  # Example input size (can be changed)\n",
    "output_size = dim   # Binary classification (sigmoid output for single output)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "batch_size = 64\n",
    "t_X_train = torch.tensor(X_train)\n",
    "t_y_train = torch.tensor(y_train)\n",
    "dataset = TensorDataset(t_X_train, t_y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate the inverse_model, loss function, and optimizer\n",
    "inverse_model = NNinv(input_size, output_size)\n",
    "loss_fn = nn.L1Loss()  # Mean Absolute Error (MAE)\n",
    "optimizer = optim.Adam(inverse_model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs to train\n",
    "num_epochs = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        # Forward pass\n",
    "        outputs = inverse_model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the epoch\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "t_X_test = torch.tensor(X_test)\n",
    "t_y_test = torch.tensor(y_test)\n",
    "outputs_test = inverse_model(t_X_test)\n",
    "loss_test = loss_fn(outputs_test, t_y_test)\n",
    "print(loss_test/y_test.shape[0])\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# Create a figure and 3D axis\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Define colors for each Gaussian distribution\n",
    "# colors = ['r', 'g', 'b']  # Red, Green, Blue\n",
    "\n",
    "\n",
    "output_fin = outputs_test.detach().numpy()\n",
    "# Loop through each Gaussian to plot points with corresponding color\n",
    "for i in range(n_gauss):\n",
    "    ax.scatter(t_y_test[c_test == i, 0], t_y_test[c_test == i, 1], t_y_test[c_test == i, 2], color=colors[i], label=f'Actual_Gaussian {i+1}')\n",
    "    # ax.scatter(output_fin[c_test == i, 0], output_fin[c_test == i, 1], output_fin[c_test == i, 2], color='orange', label=f'Predicted_Gaussian {i+1}')\n",
    "\n",
    "ax.scatter(output_fin[:, 0], output_fin[:, 1], output_fin[:, 2], color='orange', label=f'Predicted_Gaussians')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "ax.set_title('TSNE \\n Actual Vs Prediction')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a 2D Grid for Jacobian Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.52948 32.871674\n",
      "-25.627789 26.346518\n",
      "(100, 100)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# Define min and max values\n",
    "x_min, x_max = np.min(S[:, 0]), np.max(S[:, 0])\n",
    "y_min, y_max = np.min(S[:, 1]), np.max(S[:, 1])\n",
    "print(x_min, x_max)\n",
    "print(y_min, y_max)\n",
    "\n",
    "# Define grid resolution\n",
    "num_grid_points = 100\n",
    "\n",
    "# Generate grid\n",
    "x_vals = np.linspace(x_min, x_max, num_grid_points)\n",
    "y_vals = np.linspace(y_min, y_max, num_grid_points)\n",
    "xx, yy = np.meshgrid(x_vals, y_vals)\n",
    "print(yy.shape)\n",
    "print(y_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Visualize the grid on top of the t-SNE data\n",
    "plt.scatter(S[:, 0], S[:, 1], c='blue', s=10, label=\"t-SNE Output\")\n",
    "plt.scatter(xx, yy, c='red', s=5, label=\"Grid Points\")\n",
    "plt.title(\"2D t-SNE Output with Grid Points\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jacobian(x, y):\n",
    "    \"\"\"\n",
    "    Computes the Jacobian matrix for each point in the grid.\n",
    "    \n",
    "    Args:\n",
    "        grid_points (ndarray): A 2D array of shape (n_points, 2) representing the grid points.\n",
    "\n",
    "    Returns:\n",
    "        jacobian_matrices (list): A list of jacobian matrices for each grid point.\n",
    "    \"\"\"\n",
    "    jacobian_matrices = []\n",
    "    \n",
    "    # Define the model's forward pass to use autograd\n",
    "    def model_forward(input):\n",
    "        return inverse_model(input)  # Model's forward pass\n",
    "    \n",
    "    # Iterate through the grid points\n",
    "    # for point in grid_points:\n",
    "    point_tensor = torch.tensor([x, y], dtype=torch.float32, requires_grad=True)  # (1, 2) tensor\n",
    "    \n",
    "    # Compute the Jacobian using autograd's jacobian function\n",
    "    jacobian = torch.autograd.functional.jacobian(model_forward, point_tensor)\n",
    "    \n",
    "        # The output of jacobian will have shape (1, 3, 2), so we need to squeeze to get (3, 2)\n",
    "        # jacobian_matrices.append(jacobian.squeeze(0))  # Remove the batch dimension\n",
    "    \n",
    "    return jacobian\n",
    "\n",
    "# ### Function to compute Jacobian at a specific point\n",
    "# def compute_jacobian_implement(x, y, eps):\n",
    "#     # eps = 1e-5  # Small epsilon for numerical differentiation\n",
    "\n",
    "#     # Partial derivatives with respect to x \n",
    "#     point_hor_plus = torch.tensor([[x + eps, y]]) \n",
    "#     point_hor_minus = torch.tensor([[x - eps, y]]) \n",
    "#     f_x_plus_eps = inverse_model(point_hor_plus).detach().numpy()   #3D output\n",
    "#     f_x_minus_eps = inverse_model(point_hor_minus).detach().numpy()\n",
    "#     df_dx = (f_x_plus_eps - f_x_minus_eps) / (2 * eps)\n",
    "\n",
    "#     # Partial derivatives with respect to y\n",
    "#     point_ver_plus = torch.tensor([[x , y + eps]]) \n",
    "#     point_ver_minus = torch.tensor([[x , y - eps]]) \n",
    "#     f_y_plus_eps = inverse_model(point_ver_plus).detach().numpy()\n",
    "#     f_y_minus_eps = inverse_model(point_ver_minus).detach().numpy()\n",
    "#     df_dy = (f_y_plus_eps - f_y_minus_eps) / (2 * eps)\n",
    "\n",
    "#     # Jacobian matrix 3x2\n",
    "#     J = np.column_stack((df_dx.T, df_dy.T))\n",
    "#     return J\n",
    "###################################################################################################\n",
    "# def compute_jacobian_implement(x, y, eps):\n",
    "#     # Create tensors for the input points\n",
    "#     point_hor_plus = torch.tensor([[x + eps, y]], dtype=torch.float32) \n",
    "#     point_hor_minus = torch.tensor([[x - eps, y]], dtype=torch.float32)\n",
    "#     point_ver_plus = torch.tensor([[x, y + eps]], dtype=torch.float32)\n",
    "#     point_ver_minus = torch.tensor([[x, y - eps]], dtype=torch.float32)\n",
    "    \n",
    "#     # Evaluate function at shifted points\n",
    "#     f_x_plus_eps = inverse_model(point_hor_plus).detach().numpy().squeeze()  # Ensure 1D\n",
    "#     f_x_minus_eps = inverse_model(point_hor_minus).detach().numpy().squeeze()\n",
    "#     f_y_plus_eps = inverse_model(point_ver_plus).detach().numpy().squeeze()\n",
    "#     f_y_minus_eps = inverse_model(point_ver_minus).detach().numpy().squeeze()\n",
    "    \n",
    "#     # Compute partial derivatives using finite differences\n",
    "#     df_dx = (f_x_plus_eps - f_x_minus_eps) / (2 * eps)\n",
    "#     df_dy = (f_y_plus_eps - f_y_minus_eps) / (2 * eps)\n",
    "    \n",
    "#     # Construct the Jacobian (3x2 matrix)\n",
    "#     J = np.column_stack((df_dx, df_dy))\n",
    "#     return J\n",
    "\n",
    "\n",
    "def compute_jacobian_implement(x, y, eps=1e-5):\n",
    "    # Create tensor point for cloning\n",
    "    point = torch.tensor([[x, y]], dtype=torch.float32)\n",
    "\n",
    "    # Partial derivative w.r.t. x using five-point stencil\n",
    "    f_x_2plus = inverse_model(torch.tensor([[x + 2 * eps, y]], dtype=torch.float32))\n",
    "    f_x_plus = inverse_model(torch.tensor([[x + eps, y]], dtype=torch.float32))\n",
    "    f_x_minus = inverse_model(torch.tensor([[x - eps, y]], dtype=torch.float32))\n",
    "    f_x_2minus = inverse_model(torch.tensor([[x - 2 * eps, y]], dtype=torch.float32))\n",
    "    \n",
    "    df_dx = (-f_x_2plus + 8 * f_x_plus - 8 * f_x_minus + f_x_2minus) / (12 * eps)\n",
    "\n",
    "    # Partial derivative w.r.t. y using five-point stencil\n",
    "    f_y_2plus = inverse_model(torch.tensor([[x, y + 2 * eps]], dtype=torch.float32))\n",
    "    f_y_plus = inverse_model(torch.tensor([[x, y + eps]], dtype=torch.float32))\n",
    "    f_y_minus = inverse_model(torch.tensor([[x, y - eps]], dtype=torch.float32))\n",
    "    f_y_2minus = inverse_model(torch.tensor([[x, y - 2 * eps]], dtype=torch.float32))\n",
    "    \n",
    "    df_dy = (-f_y_2plus + 8 * f_y_plus - 8 * f_y_minus + f_y_2minus) / (12 * eps)\n",
    "\n",
    "    # Stack results to form Jacobian matrix\n",
    "    jacobian = torch.stack([df_dx.squeeze(), df_dy.squeeze()], dim=1)\n",
    "    \n",
    "    return jacobian.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Jacobians over the grid and store results\n",
    "jacobians = []\n",
    "for i in range(num_grid_points):\n",
    "    for j in range(num_grid_points):\n",
    "        x, y = xx[i, j], yy[i, j]\n",
    "        # print(x,y)\n",
    "        jacobian_mt = compute_jacobian_implement(x, y, 1e-5)\n",
    "        # jacobian_mt = compute_jacobian(x, y)\n",
    "        # print(jacobian)\n",
    "        jacobians.append(jacobian_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping jacobina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacobians[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02483527, -0.03476938],\n",
       "       [-0.01564622,  0.01316269],\n",
       "       [ 0.02135833, -0.02880891]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 3, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of numpy arrays into a list of PyTorch tensors\n",
    "jacobian_tensors = [torch.tensor(jacob) for jacob in jacobians]\n",
    "\n",
    "# Convert the list into a 3D tensor\n",
    "jacobian_tensor = torch.stack(jacobian_tensors)  # Shape will be [num_grids * num_grids, 3, 2]\n",
    "\n",
    "# Reshape the tensor to [num_grids, num_grids, 3, 2]\n",
    "jacobian_tensor_reshaped = jacobian_tensor.view(num_grid_points, num_grid_points, 3, 2)\n",
    "jacobian_tensor_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigne_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compute the eigenvalues of J^T J for each Jacobian matrix\n",
    "eigenvalues = np.zeros((num_grid_points, num_grid_points, 2))  # Store two eigenvalues per J^T J (2x2 matrix)\n",
    "\n",
    "for i in range(num_grid_points):\n",
    "    for j in range(num_grid_points):\n",
    "        jacobian = jacobian_tensor_reshaped[i, j]  # Get the 3x2 Jacobian matrix\n",
    "        gram_matrix = jacobian.T @ jacobian  # Compute the 2x2 J^T J matrix\n",
    "        eigvals = torch.linalg.eigvals(gram_matrix)  # Eigenvalues of J^T J\n",
    "        eigenvalues[i, j] = eigvals.real.numpy()  # Store only real parts if complex\n",
    "\n",
    "# Visualize the largest eigenvalue across the grid to identify sensitive areas\n",
    "largest_eigenvalue = np.max(eigenvalues, axis=2)\n",
    "# sqrt_large_eig_val = np.sqrt(largest_eigenvalue)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(largest_eigenvalue, cmap=\"hot\")\n",
    "# plt.imshow(sqrt_large_eig_val, cmap=\"hot\")\n",
    "plt.colorbar(label=\"Largest Eigenvalue of J^T J (Sensitivity)\")\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.title(\"Heatmap of Largest Eigenvalue (Sensitive Regions)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerically & Analytically Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbolic Jacobian:\n",
      " [[ 0.87758256  1.        ]\n",
      " [-1.          0.47942554]\n",
      " [ 1.         -1.        ]]\n",
      "Numerical Jacobian:\n",
      " [[[ 0.87758255  1.        ]]\n",
      "\n",
      " [[-1.          0.47942555]]\n",
      "\n",
      " [[ 1.         -1.        ]]]\n",
      "Implementation [[ 0.87966526  1.0016065 ]\n",
      " [-1.0016065   0.4803141 ]\n",
      " [ 1.0016065  -1.001358  ]]\n",
      "Difference:\n",
      " [[ 0.00208269  0.00160646]\n",
      " [-0.00160646  0.00088857]\n",
      " [ 0.00160646 -0.00135803]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define the analytic function f\n",
    "def analytic_function(point):\n",
    "    x, y = point[:, 0], point[:, 1]\n",
    "    z1 = torch.sin(x) + y\n",
    "    z2 = torch.cos(y) - x\n",
    "    z3 = x**2 + y**2\n",
    "    return torch.stack([z1, z2, z3], dim=1)\n",
    "\n",
    "# Define symbolic Jacobian for testing\n",
    "def symbolic_jacobian(x, y):\n",
    "    J = np.array([\n",
    "        [np.cos(x), 1],\n",
    "        [-1, -np.sin(y)],\n",
    "        [2 * x, 2 * y]\n",
    "    ])\n",
    "    return J\n",
    "\n",
    "# Numerical Jacobian function\n",
    "def compute_jacobian_autograd_single_point(func, point):\n",
    "    point_tensor = torch.tensor([point], dtype=torch.float32, requires_grad=True)\n",
    "    jacobian = torch.autograd.functional.jacobian(func, point_tensor).squeeze(0)\n",
    "    return jacobian.detach().numpy()\n",
    "\n",
    "def compute_jacobian_implement_analytic(x, y, eps=1e-5):\n",
    "    # Create tensor point for cloning\n",
    "    point = torch.tensor([[x, y]], dtype=torch.float32)\n",
    "\n",
    "    # Partial derivative w.r.t. x using five-point stencil\n",
    "    f_x_2plus = analytic_function(torch.tensor([[x + 2 * eps, y]], dtype=torch.float32))\n",
    "    f_x_plus = analytic_function(torch.tensor([[x + eps, y]], dtype=torch.float32))\n",
    "    f_x_minus = analytic_function(torch.tensor([[x - eps, y]], dtype=torch.float32))\n",
    "    f_x_2minus = analytic_function(torch.tensor([[x - 2 * eps, y]], dtype=torch.float32))\n",
    "    \n",
    "    df_dx = (-f_x_2plus + 8 * f_x_plus - 8 * f_x_minus + f_x_2minus) / (12 * eps)\n",
    "\n",
    "    # Partial derivative w.r.t. y using five-point stencil\n",
    "    f_y_2plus = analytic_function(torch.tensor([[x, y + 2 * eps]], dtype=torch.float32))\n",
    "    f_y_plus = analytic_function(torch.tensor([[x, y + eps]], dtype=torch.float32))\n",
    "    f_y_minus = analytic_function(torch.tensor([[x, y - eps]], dtype=torch.float32))\n",
    "    f_y_2minus = analytic_function(torch.tensor([[x, y - 2 * eps]], dtype=torch.float32))\n",
    "    \n",
    "    df_dy = (-f_y_2plus + 8 * f_y_plus - 8 * f_y_minus + f_y_2minus) / (12 * eps)\n",
    "\n",
    "    # Stack results to form Jacobian matrix\n",
    "    jacobian = torch.stack([df_dx.squeeze(), df_dy.squeeze()], dim=1)\n",
    "    \n",
    "    return jacobian.detach().numpy()\n",
    "\n",
    "# Define a grid point for testing\n",
    "x = 0.5\n",
    "y = -0.5\n",
    "test_point = np.array([x, y])\n",
    "\n",
    "# Compute the symbolic Jacobian\n",
    "symbolic_J = symbolic_jacobian(test_point[0], test_point[1])\n",
    "\n",
    "# Compute the numerical Jacobian using autograd\n",
    "numerical_J = compute_jacobian_autograd_single_point(analytic_function, test_point)\n",
    "\n",
    "implent_j = compute_jacobian_implement_analytic(x, y, 1e-5)\n",
    "\n",
    "# Compare the results\n",
    "print(\"Symbolic Jacobian:\\n\", symbolic_J)\n",
    "print(\"Numerical Jacobian:\\n\", numerical_J)\n",
    "print('Implementation', implent_j)\n",
    "print(\"Difference:\\n\", implent_j - symbolic_J)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse-projection-j9xKauoB-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
